{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A bunch of imports, you don't have to worry about these\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import gym\n",
    "import glob\n",
    "import io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q_values_SMDP = np.zeros((500,10))\n",
    "R_option_policy=np.zeros((25,4)) # action 6\n",
    "G_option_policy=np.zeros((25,4)) # action 7 \n",
    "B_option_policy=np.zeros((25,4)) # action 8 \n",
    "Y_option_policy=np.zeros((25,4)) # action 9\n",
    "update_frequency=np.zeros((500,10))\n",
    "avl_actions = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "def egreedy_policy_2(q_values,state,epsilon):\n",
    "  if np.random.rand() < epsilon:\n",
    "        return np.random.randint(0,4)\n",
    "  else:\n",
    "        state_row,state_col,_,_=list(env.decode(state))\n",
    "        state_no = state_row*5+state_col\n",
    "        return np.argmax(q_values[state_no])\n",
    "  \n",
    "def egreedy_policy(q_values, state, epsilon,disallow,rg):\n",
    "    if (rg.random() < epsilon):   # epsilon prob for uniform choice over all actions and options\n",
    "        if (disallow != None):\n",
    "            val_actions = avl_actions[:]; val_actions.remove(disallow)\n",
    "            return rg.choice(val_actions)\n",
    "        else:\n",
    "            return rg.choice(avl_actions)\n",
    "    else:                         # 1 - epsilon prob for greedy action/option\n",
    "            return np.argmax(q_values[state])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "6\n",
      "2\n",
      "----\n",
      "(328, {'prob': 1.0, 'action_mask': array([1, 1, 1, 0, 0, 0], dtype=int8)}) state\n",
      "----\n",
      "2\n",
      "----\n",
      "348 nextstate\n",
      "-1\n",
      "False\n",
      "False\n",
      "{'prob': 1.0, 'action_mask': array([1, 1, 0, 1, 0, 0], dtype=int8)}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "seed = 543\n",
    "#Setting up the environment\n",
    "env = gym.make('Taxi-v3')\n",
    "env.reset(seed=seed)\n",
    "\n",
    "state_shape = env.observation_space.shape\n",
    "no_of_actions = env.action_space.n\n",
    "\n",
    "print(state_shape)\n",
    "print(no_of_actions)\n",
    "print(env.action_space.sample())\n",
    "print(\"----\")\n",
    "\n",
    "state = env.reset()\n",
    "''' This returns the initial state (when environment is reset) '''\n",
    "\n",
    "print(state,\"state\")\n",
    "print(\"----\")\n",
    "\n",
    "action = env.action_space.sample()\n",
    "''' We take a random action now '''\n",
    "\n",
    "print(action)\n",
    "print(\"----\")\n",
    "\n",
    "next_state, reward, terminated, truncated, info = env.step(action)\n",
    "''' env.step is used to calculate new state and obtain reward based on old state and action taken  '''\n",
    "\n",
    "print(next_state,\"nextstate\")\n",
    "print(reward)\n",
    "print(terminated)\n",
    "print(truncated)\n",
    "print(info)\n",
    "print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_R(env, state,q):\n",
    "    coords = list(env.decode(state))[:2]\n",
    "    optdone = False\n",
    "    optact = egreedy_policy_2(q,state,0.9)\n",
    "    if (coords == [0, 0]): # termination at reaching RED\n",
    "        optdone = True\n",
    "    return [optact, optdone]\n",
    "\n",
    "def learn_G(env, state,q):\n",
    "    coords = list(env.decode(state))[:2]\n",
    "    optdone = False\n",
    "    optact = egreedy_policy_2(q,state,0.9)\n",
    "    if (coords == [0, 4]): # termination at reaching RED\n",
    "        optdone = True\n",
    "    return [optact, optdone]\n",
    "\n",
    "def learn_Y(env, state,q):\n",
    "    coords = list(env.decode(state))[:2]\n",
    "    optdone = False\n",
    "    optact = egreedy_policy_2(q,state,0.9)\n",
    "    if (coords == [4, 0]): # termination at reaching RED\n",
    "        optdone = True\n",
    "    return [optact, optdone]\n",
    "\n",
    "def learn_B(env, state,q):\n",
    "    coords = list(env.decode(state))[:2]\n",
    "    optdone = False\n",
    "    optact = egreedy_policy_2(q,state,0.9)\n",
    "    if (coords == [4, 3]): # termination at reaching RED\n",
    "        optdone = True\n",
    "    return [optact, optdone]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q_values_SMDP = np.zeros((500,10))\n",
    "R_option_policy=np.zeros((25,4)) # action 6\n",
    "G_option_policy=np.zeros((25,4)) # action 7 \n",
    "B_option_policy=np.zeros((25,4)) # action 8 \n",
    "Y_option_policy=np.zeros((25,4)) # action 9\n",
    "update_frequency=np.zeros((500,10))\n",
    "avl_actions = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "def egreedy_policy_2(q_values,state,epsilon):\n",
    "  if np.random.rand() < epsilon:\n",
    "        return np.random.randint(0,4)\n",
    "  else:\n",
    "        state_row,state_col,_,_=list(env.decode(state))\n",
    "        state_no = state_row*5+state_col\n",
    "        return np.argmax(q_values[state_no])\n",
    "  \n",
    "def egreedy_policy(q_values, state, epsilon,disallow,rg):\n",
    "    if (rg.random() < epsilon):   # epsilon prob for uniform choice over all actions and options\n",
    "        if (disallow != None):\n",
    "            val_actions = avl_actions[:]; val_actions.remove(disallow)\n",
    "            return rg.choice(val_actions)\n",
    "        else:\n",
    "            return rg.choice(avl_actions)\n",
    "    else:                         # 1 - epsilon prob for greedy action/option\n",
    "            return np.argmax(q_values[state])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:42<00:00, 237.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  \n",
    "episode_rewards = []\n",
    "\n",
    "gamma =0.9\n",
    "alpha =  0.338\n",
    "epsilon = 0.144\n",
    "for _ in tqdm(range(10000)):\n",
    "    \n",
    "    state, _ = env.reset()   \n",
    "    #print(state)\n",
    "    done = False\n",
    "    total_reward = 0  \n",
    "    while not done:\n",
    "        st_coords = tuple(env.decode(state))[:2]\n",
    "        \n",
    "        dis_opts = {(0,0) : 6, (0,4) : 7, (4,0) : 8, (4,3) : 9} \n",
    "        dis_opt = (dis_opts[st_coords] if st_coords in dis_opts.keys() else None) \n",
    "        action = egreedy_policy(q_values_SMDP, state, epsilon, dis_opt,rg= np.random.RandomState(42))   \n",
    "        if action < 6:\n",
    "            next_state, reward, terminated, truncated, info = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            \n",
    "            q_values_SMDP[state][action] += alpha * (reward + gamma * np.max(q_values_SMDP[next_state]) - q_values_SMDP[state][action])\n",
    "            update_frequency[state][action] += 1\n",
    "            \n",
    "            state = next_state\n",
    "            total_reward += reward \n",
    "        reward_bar = 0\n",
    "        s_state = state\n",
    "        if action == 6: \n",
    "            k = 0\n",
    "            state_row,state_col,_,_=list(env.decode(state))\n",
    "            pos=[state_row,state_col]\n",
    "            optdone = False\n",
    "            while not optdone:\n",
    "                k += 1\n",
    "                state_no=state_row*5+state_col\n",
    "                optact, optdone = learn_R(env, state,R_option_policy) \n",
    "                next_state, reward, terminated, truncated, info = env.step(optact)\n",
    "                done = terminated or truncated\n",
    "                state_row,state_col,_,_=list(env.decode(next_state))\n",
    "                next_state_no=state_row*5+state_col\n",
    "                R_option_policy[state_no][optact] += alpha * (reward + gamma * np.max(R_option_policy[next_state_no]) - R_option_policy[state_no][optact])\n",
    "                state = next_state\n",
    "                reward_bar = gamma * reward_bar + reward\n",
    "                state_row,state_col,_,_=list(env.decode(state))\n",
    "                pos=[state_row,state_col]\n",
    "                \n",
    "            q_values_SMDP[s_state][6] += alpha * (reward_bar + (gamma ** k) * np.max(q_values_SMDP[next_state]) - q_values_SMDP[s_state][6])\n",
    "            update_frequency[state][6] += 1\n",
    "            total_reward += reward_bar  \n",
    "        if action == 7:  \n",
    "            k=0\n",
    "            state_row,state_col,_,_=list(env.decode(state))\n",
    "            pos=[state_row,state_col]\n",
    "            optdone = False\n",
    "            while (optdone == False):\n",
    "                k+=1\n",
    "                state_no=state_row*5+state_col\n",
    "                optact,optdone = learn_G(env,state,G_option_policy) \n",
    "                next_state, reward, terminated, truncated, info = env.step(optact)\n",
    "                done = terminated or truncated\n",
    "                state_row,state_col,_,_=list(env.decode(next_state))\n",
    "                next_state_no=state_row*5+state_col\n",
    "                G_option_policy[state_no][optact] += alpha * (reward + gamma * np.max(R_option_policy[next_state_no]) - R_option_policy[state_no][optact])\n",
    "                state = next_state\n",
    "                reward_bar = gamma*reward_bar + reward\n",
    "                state_row,state_col,_,_=list(env.decode(state))\n",
    "                pos=[state_row,state_col]\n",
    "                \n",
    "            q_values_SMDP[s_state][7] += alpha * (reward_bar + (gamma**k) * np.max(q_values_SMDP[next_state]) - q_values_SMDP[s_state][7])\n",
    "            update_frequency[state][7]+=1\n",
    "            total_reward += reward_bar\n",
    "\n",
    "        if action == 8: \n",
    "                k=0\n",
    "                optdone = False\n",
    "                state_row,state_col,_,_=list(env.decode(state))\n",
    "                pos=[state_row,state_col]\n",
    "                while (optdone == False):\n",
    "                    k+=1\n",
    "                    state_no=state_row*5+state_col\n",
    "                    optact,optdone = learn_Y(env,state,Y_option_policy) \n",
    "                    next_state, reward, terminated, truncated, info = env.step(optact)\n",
    "                    done = terminated or truncated\n",
    "                    state_row,state_col,_,_=list(env.decode(next_state))\n",
    "                    next_state_no=state_row*5+state_col\n",
    "                    Y_option_policy[state_no][optact] += alpha * (reward + gamma * np.max(R_option_policy[next_state_no]) - R_option_policy[state_no][optact])\n",
    "                    state = next_state\n",
    "                    reward_bar = gamma*reward_bar + reward\n",
    "                    state_row,state_col,_,_=list(env.decode(state))\n",
    "                    pos=[state_row,state_col]\n",
    "                q_values_SMDP[s_state][8] += alpha * (reward_bar + (gamma**k) * np.max(q_values_SMDP[next_state]) - q_values_SMDP[s_state][8])\n",
    "                \n",
    "                update_frequency[state][8]+=1\n",
    "                total_reward += reward_bar\n",
    "\n",
    "        if action == 9: \n",
    "                k=0\n",
    "                optdone = False\n",
    "                state_row,state_col,_,_=list(env.decode(state))\n",
    "                pos=[state_row,state_col]\n",
    "                while (optdone == False):\n",
    "                    k+=1\n",
    "                    state_no=state_row*5+state_col\n",
    "                    optact,optdone = learn_B(env,state,B_option_policy) \n",
    "                    next_state, reward, terminated, truncated, info = env.step(optact)\n",
    "                    done = terminated or truncated\n",
    "                    state_row,state_col,_,_=list(env.decode(next_state))\n",
    "                    next_state_no=state_row*5+state_col\n",
    "                    B_option_policy[state_no][optact] += alpha * (reward + gamma * np.max(R_option_policy[next_state_no]) - R_option_policy[state_no][optact])\n",
    "                    state = next_state\n",
    "                    reward_bar = gamma*reward_bar + reward\n",
    "                    state_row,state_col,_,_=list(env.decode(state))\n",
    "                    pos=[state_row,state_col]\n",
    "                q_values_SMDP[s_state][9] += alpha * (reward_bar + (gamma**k) * np.max(q_values_SMDP[next_state]) - q_values_SMDP[s_state][9])\n",
    "                update_frequency[state][9]+=1\n",
    "                total_reward += reward_bar\n",
    "\n",
    "   \n",
    "        if done:\n",
    "            episode_rewards.append(total_reward) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_smdp = q_values_SMDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_rewards_smdp = episode_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q-Table: (States x Actions) === (env.ns(48) x total actions(6))\n",
    "q_values_ioql = np.zeros((500,10))\n",
    "R_option_policy=np.zeros((25,4)) # action 6\n",
    "G_option_policy=np.zeros((25,4)) # action 7 \n",
    "B_option_policy=np.zeros((25,4)) # action 8 \n",
    "Y_option_policy=np.zeros((25,4)) # action 9\n",
    "\n",
    "#Update_Frequency Data structure? Check TODO 4\n",
    "update_frequency=np.zeros((500,10))\n",
    "avl_actions = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "#avl_actions = [6, 7, 8, 9]\n",
    "# TODO: epsilon-greedy action selection function\n",
    "def egreedy_policy_2(q_values,state,epsilon):\n",
    "  if np.random.rand() < epsilon:\n",
    "        return np.random.randint(0,4)\n",
    "  else:\n",
    "        state_row,state_col,_,_=list(env.decode(state))\n",
    "        state_no = state_row*5+state_col\n",
    "        return np.argmax(q_values[state_no])\n",
    "  \n",
    "def egreedy_policy(q_values, state, epsilon,disallow,rg):\n",
    "    if (rg.random() < epsilon):   # epsilon prob for uniform choice over all actions and options\n",
    "        if (disallow != None):\n",
    "            val_actions = avl_actions[:]; val_actions.remove(disallow)\n",
    "            return rg.choice(val_actions)\n",
    "        else:\n",
    "            return rg.choice(avl_actions)\n",
    "    else:                         # 1 - epsilon prob for greedy action/option\n",
    "            return np.argmax(q_values[state])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_R(env, state,q):\n",
    "    coords = list(env.decode(state))[:2]\n",
    "    optdone = False\n",
    "    optact = egreedy_policy_2(q,state,0.9)\n",
    "    if (coords == [0, 0]): # termination at reaching RED\n",
    "        optdone = True\n",
    "    return [optact, optdone]\n",
    "\n",
    "def learn_G(env, state,q):\n",
    "    coords = list(env.decode(state))[:2]\n",
    "    optdone = False\n",
    "    optact = egreedy_policy_2(q,state,0.9)\n",
    "    if (coords == [0, 4]): # termination at reaching RED\n",
    "        optdone = True\n",
    "    return [optact, optdone]\n",
    "\n",
    "def learn_Y(env, state,q):\n",
    "    coords = list(env.decode(state))[:2]\n",
    "    optdone = False\n",
    "    optact = egreedy_policy_2(q,state,0.9)\n",
    "    if (coords == [4, 0]): # termination at reaching RED\n",
    "        optdone = True\n",
    "    return [optact, optdone]\n",
    "\n",
    "def learn_B(env, state,q):\n",
    "    coords = list(env.decode(state))[:2]\n",
    "    optdone = False\n",
    "    optact = egreedy_policy_2(q,state,0.9)\n",
    "    if (coords == [4, 3]): # termination at reaching RED\n",
    "        optdone = True\n",
    "    return [optact, optdone]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "RED_TERM_MATRIX = np.zeros((5,5)); RED_TERM_MATRIX[0,0] = 1\n",
    "GRE_TERM_MATRIX = np.zeros((5,5)); GRE_TERM_MATRIX[0,4] = 1\n",
    "YEL_TERM_MATRIX = np.zeros((5,5)); YEL_TERM_MATRIX[4,0] = 1\n",
    "BLU_TERM_MATRIX = np.zeros((5,5)); BLU_TERM_MATRIX[4,3] = 1\n",
    "\n",
    "OPT_TO_TERM_MAP = {6 : RED_TERM_MATRIX, 7 : GRE_TERM_MATRIX, 8 :YEL_TERM_MATRIX, 9 : BLU_TERM_MATRIX}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:30<00:00, 330.65it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  # tqdm is a library for displaying progress bars\n",
    "\n",
    "# Initialize episode_rewards list to store rewards obtained during each episode\n",
    "episode_rewards = []\n",
    "\n",
    "# Add parameters you might need here\n",
    "gamma = 0.9\n",
    "alpha =  0.14008\n",
    "epsilon =0.142886\n",
    "# Iterate over 1000 episodes\n",
    "for _ in tqdm(range(10000)):\n",
    "    \n",
    "    state, _ = env.reset()   \n",
    "    #print(state)\n",
    "    done = False\n",
    "    total_reward = 0  # Initialize total reward for the episode\n",
    "\n",
    "    # While episode is not over\n",
    "    while not done:\n",
    "       \n",
    "        \n",
    "        # Choose action  \n",
    "        st_coords = tuple(env.decode(state))[:2]\n",
    "        \n",
    "        dis_opts = {(0,0) : 6, (0,4) : 7, (4,0) : 8, (4,3) : 9} \n",
    "        dis_opt = (dis_opts[st_coords] if st_coords in dis_opts.keys() else None) \n",
    "        action = egreedy_policy(q_values_ioql, state, epsilon, dis_opt,rg= np.random.RandomState(42))   \n",
    "        #print(action,st_coords,\"hello\")\n",
    "        #action = egreedy_policy(q_values_SMDP, state, epsilon)\n",
    "        # Checking if primitive action\n",
    "        if action < 6:\n",
    "            # Perform regular Q-Learning update for state-action pair\n",
    "            next_state, reward, terminated, truncated, info = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            \n",
    "            q_values_ioql[state][action] += alpha * (reward + gamma * np.max(q_values_ioql[next_state]) - q_values_ioql[state][action])\n",
    "            update_frequency[state][action] += 1\n",
    "            \n",
    "            state = next_state\n",
    "            total_reward += reward  # Accumulate reward for the episode\n",
    "        \n",
    "        # Checking if action chosen is an option\n",
    "        reward_bar = 0\n",
    "        s_state = state\n",
    "        if action == 6: # action => Away option\n",
    "            k = 0\n",
    "            state_row,state_col,_,_=list(env.decode(state))\n",
    "            pos=[state_row,state_col]\n",
    "            optdone = False\n",
    "            while not optdone:\n",
    "                k += 1\n",
    "                state_no=state_row*5+state_col\n",
    "                optact, optdone = learn_R(env, state,R_option_policy) \n",
    "                next_state, reward, terminated, truncated, info = env.step(optact)\n",
    "                done = terminated or truncated\n",
    "                state_row,state_col,_,_=list(env.decode(next_state))\n",
    "                next_state_no=state_row*5+state_col\n",
    "                q_values_ioql[state, optact] += alpha * (reward + gamma*np.max(q_values_ioql[next_state]) - q_values_ioql[state, optact])\n",
    "                update_frequency[state, optact] += 1\n",
    "                R_option_policy[state_no][optact] += alpha * (reward + gamma * np.max(R_option_policy[next_state_no]) - R_option_policy[state_no][optact])\n",
    "                options_to_update = [action]\n",
    "                st_coords = list(env.decode(state))[:2]\n",
    "                other_options = [7,8,9]\n",
    "                for oth in other_options:\n",
    "                    if oth == 7:\n",
    "                        pa,pd = learn_G(env,state,G_option_policy)\n",
    "                        if pa == optact:\n",
    "                            options_to_update.append(oth)\n",
    "                    if oth == 8:\n",
    "                        pa,pd = learn_Y(env,state,G_option_policy)\n",
    "                        if pa == optact:\n",
    "                            options_to_update.append(oth)\n",
    "                    if oth == 9:\n",
    "                        pa,pd = learn_B(env,state,G_option_policy)\n",
    "                        if pa == optact:\n",
    "                            options_to_update.append(oth)\n",
    "                nst_coords = list(env.decode(next_state))[:2]\n",
    "                for opt in options_to_update:\n",
    "                        term_matrix = OPT_TO_TERM_MAP[opt]\n",
    "                        if term_matrix[nst_coords[0], nst_coords[1]] == 1:\n",
    "                            # if the option terminates, we do total max over all actions(and options) in next state\n",
    "                            q_values_ioql[state, opt] += alpha * (reward + gamma * np.max(q_values_ioql[next_state]) - q_values_ioql[state, opt])\n",
    "                            update_frequency[state, opt] += 1\n",
    "                        else:\n",
    "                            # if it does not, we use the option q-value in next state for update\n",
    "                            q_values_ioql[state, opt] += alpha * (reward + gamma * (q_values_ioql[next_state, opt]) - q_values_ioql[state, opt])\n",
    "                            update_frequency[state, opt] += 1\n",
    "                state = next_state\n",
    "\n",
    "                reward_bar = gamma * reward_bar + reward\n",
    "                state_row,state_col,_,_=list(env.decode(state))\n",
    "                pos=[state_row,state_col]\n",
    "                \n",
    "            #q_values_SMDP[s_state][6] += alpha * (reward_bar + (gamma ** k) * np.max(q_values_SMDP[next_state]) - q_values_SMDP[s_state][6])\n",
    "            #update_frequency[state][6] += 1\n",
    "            total_reward += reward_bar  # Accumulate reward for the episode\n",
    "\n",
    "        # Update state for other option actions (similar to action 6)\n",
    "        if action == 7: # action => Away option\n",
    "            k = 0\n",
    "            state_row,state_col,_,_=list(env.decode(state))\n",
    "            pos=[state_row,state_col]\n",
    "            optdone = False\n",
    "            while not optdone:\n",
    "                k += 1\n",
    "                state_no=state_row*5+state_col\n",
    "                optact, optdone = learn_G(env, state,R_option_policy) \n",
    "                next_state, reward, terminated, truncated, info = env.step(optact)\n",
    "                done = terminated or truncated\n",
    "                state_row,state_col,_,_=list(env.decode(next_state))\n",
    "                next_state_no=state_row*5+state_col\n",
    "                q_values_ioql[state, optact] += alpha * (reward + gamma*np.max(q_values_ioql[next_state]) - q_values_ioql[state, optact])\n",
    "                update_frequency[state, optact] += 1\n",
    "                R_option_policy[state_no][optact] += alpha * (reward + gamma * np.max(R_option_policy[next_state_no]) - R_option_policy[state_no][optact])\n",
    "                options_to_update = [action]\n",
    "                st_coords = list(env.decode(state))[:2]\n",
    "                other_options = [6,8,9]\n",
    "                for oth in other_options:\n",
    "                    if oth == 6:\n",
    "                        pa,pd = learn_R(env,state,G_option_policy)\n",
    "                        if pa == optact:\n",
    "                            options_to_update.append(oth)\n",
    "                    if oth == 8:\n",
    "                        pa,pd = learn_Y(env,state,G_option_policy)\n",
    "                        if pa == optact:\n",
    "                            options_to_update.append(oth)\n",
    "                    if oth == 9:\n",
    "                        pa,pd = learn_B(env,state,G_option_policy)\n",
    "                        if pa == optact:\n",
    "                            options_to_update.append(oth)\n",
    "                nst_coords = list(env.decode(next_state))[:2]\n",
    "                for opt in options_to_update:\n",
    "                        term_matrix = OPT_TO_TERM_MAP[opt]\n",
    "                        if term_matrix[nst_coords[0], nst_coords[1]] == 1:\n",
    "                            # if the option terminates, we do total max over all actions(and options) in next state\n",
    "                            q_values_ioql[state, opt] += alpha * (reward + gamma * np.max(q_values_ioql[next_state]) - q_values_ioql[state, opt])\n",
    "                            update_frequency[state, opt] += 1\n",
    "                        else:\n",
    "                            # if it does not, we use the option q-value in next state for update\n",
    "                            q_values_ioql[state, opt] += alpha * (reward + gamma * (q_values_ioql[next_state, opt]) - q_values_ioql[state, opt])\n",
    "                            update_frequency[state, opt] += 1\n",
    "                state = next_state\n",
    "\n",
    "                reward_bar = gamma * reward_bar + reward\n",
    "                state_row,state_col,_,_=list(env.decode(state))\n",
    "                pos=[state_row,state_col]\n",
    "                \n",
    "            #q_values_SMDP[s_state][6] += alpha * (reward_bar + (gamma ** k) * np.max(q_values_SMDP[next_state]) - q_values_SMDP[s_state][6])\n",
    "            #update_frequency[state][6] += 1\n",
    "            total_reward += reward_bar  # Accumulate reward for the episode\n",
    "\n",
    "        if action == 8: # action => Away option\n",
    "            k = 0\n",
    "            state_row,state_col,_,_=list(env.decode(state))\n",
    "            pos=[state_row,state_col]\n",
    "            optdone = False\n",
    "            while not optdone:\n",
    "                k += 1\n",
    "                state_no=state_row*5+state_col\n",
    "                optact, optdone = learn_Y(env, state,R_option_policy) \n",
    "                next_state, reward, terminated, truncated, info = env.step(optact)\n",
    "                done = terminated or truncated\n",
    "                state_row,state_col,_,_=list(env.decode(next_state))\n",
    "                next_state_no=state_row*5+state_col\n",
    "                q_values_ioql[state, optact] += alpha * (reward + gamma*np.max(q_values_ioql[next_state]) - q_values_ioql[state, optact])\n",
    "                update_frequency[state, optact] += 1\n",
    "                R_option_policy[state_no][optact] += alpha * (reward + gamma * np.max(R_option_policy[next_state_no]) - R_option_policy[state_no][optact])\n",
    "                options_to_update = [action]\n",
    "                st_coords = list(env.decode(state))[:2]\n",
    "                other_options = [6,7,9]\n",
    "                for oth in other_options:\n",
    "                    if oth == 6:\n",
    "                        pa,pd = learn_R(env,state,G_option_policy)\n",
    "                        if pa == optact:\n",
    "                            options_to_update.append(oth)\n",
    "                    if oth == 7:\n",
    "                        pa,pd = learn_G(env,state,G_option_policy)\n",
    "                        if pa == optact:\n",
    "                            options_to_update.append(oth)\n",
    "                    if oth == 9:\n",
    "                        pa,pd = learn_B(env,state,G_option_policy)\n",
    "                        if pa == optact:\n",
    "                            options_to_update.append(oth)\n",
    "                nst_coords = list(env.decode(next_state))[:2]\n",
    "                for opt in options_to_update:\n",
    "                        term_matrix = OPT_TO_TERM_MAP[opt]\n",
    "                        if term_matrix[nst_coords[0], nst_coords[1]] == 1:\n",
    "                            # if the option terminates, we do total max over all actions(and options) in next state\n",
    "                            q_values_ioql[state, opt] += alpha * (reward + gamma * np.max(q_values_ioql[next_state]) - q_values_ioql[state, opt])\n",
    "                            update_frequency[state, opt] += 1\n",
    "                        else:\n",
    "                            # if it does not, we use the option q-value in next state for update\n",
    "                            q_values_ioql[state, opt] += alpha * (reward + gamma * (q_values_ioql[next_state, opt]) - q_values_ioql[state, opt])\n",
    "                            update_frequency[state, opt] += 1\n",
    "                state = next_state\n",
    "\n",
    "                reward_bar = gamma * reward_bar + reward\n",
    "                state_row,state_col,_,_=list(env.decode(state))\n",
    "                pos=[state_row,state_col]\n",
    "                \n",
    "            #q_values_SMDP[s_state][6] += alpha * (reward_bar + (gamma ** k) * np.max(q_values_SMDP[next_state]) - q_values_SMDP[s_state][6])\n",
    "            #update_frequency[state][6] += 1\n",
    "            total_reward += reward_bar  # Accumulate reward for the episode\n",
    "\n",
    "        if action == 9: # action => Away option\n",
    "            k = 0\n",
    "            state_row,state_col,_,_=list(env.decode(state))\n",
    "            pos=[state_row,state_col]\n",
    "            optdone = False\n",
    "            while not optdone:\n",
    "                k += 1\n",
    "                state_no=state_row*5+state_col\n",
    "                optact, optdone = learn_B(env, state,R_option_policy) \n",
    "                next_state, reward, terminated, truncated, info = env.step(optact)\n",
    "                done = terminated or truncated\n",
    "                state_row,state_col,_,_=list(env.decode(next_state))\n",
    "                next_state_no=state_row*5+state_col\n",
    "                q_values_ioql[state, optact] += alpha * (reward + gamma*np.max(q_values_ioql[next_state]) - q_values_ioql[state, optact])\n",
    "                update_frequency[state, optact] += 1\n",
    "                R_option_policy[state_no][optact] += alpha * (reward + gamma * np.max(R_option_policy[next_state_no]) - R_option_policy[state_no][optact])\n",
    "                options_to_update = [action]\n",
    "                st_coords = list(env.decode(state))[:2]\n",
    "                other_options = [6,7,8]\n",
    "                for oth in other_options:\n",
    "                    if oth == 6:\n",
    "                        pa,pd = learn_R(env,state,G_option_policy)\n",
    "                        if pa == optact:\n",
    "                            options_to_update.append(oth)\n",
    "                    if oth == 7:\n",
    "                        pa,pd = learn_G(env,state,G_option_policy)\n",
    "                        if pa == optact:\n",
    "                            options_to_update.append(oth)\n",
    "                    if oth == 8:\n",
    "                        pa,pd = learn_Y(env,state,G_option_policy)\n",
    "                        if pa == optact:\n",
    "                            options_to_update.append(oth)\n",
    "                nst_coords = list(env.decode(next_state))[:2]\n",
    "                for opt in options_to_update:\n",
    "                        term_matrix = OPT_TO_TERM_MAP[opt]\n",
    "                        if term_matrix[nst_coords[0], nst_coords[1]] == 1:\n",
    "                            # if the option terminates, we do total max over all actions(and options) in next state\n",
    "                            q_values_ioql[state, opt] += alpha * (reward + gamma * np.max(q_values_ioql[next_state]) - q_values_ioql[state, opt])\n",
    "                            update_frequency[state, opt] += 1\n",
    "                        else:\n",
    "                            # if it does not, we use the option q-value in next state for update\n",
    "                            q_values_ioql[state, opt] += alpha * (reward + gamma * (q_values_ioql[next_state, opt]) - q_values_ioql[state, opt])\n",
    "                            update_frequency[state, opt] += 1\n",
    "                state = next_state\n",
    "\n",
    "                reward_bar = gamma * reward_bar + reward\n",
    "                state_row,state_col,_,_=list(env.decode(state))\n",
    "                pos=[state_row,state_col]\n",
    "                \n",
    "            #q_values_SMDP[s_state][6] += alpha * (reward_bar + (gamma ** k) * np.max(q_values_SMDP[next_state]) - q_values_SMDP[s_state][6])\n",
    "            #update_frequency[state][6] += 1\n",
    "            total_reward += reward_bar  # Accumulate reward for the episode\n",
    "\n",
    "\n",
    "        # Check if episode is done\n",
    "        if done:\n",
    "            episode_rewards.append(total_reward)  # Append total reward for the episode\n",
    "\n",
    "# Plot rewards vs. episodes\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_rewards_ioql = episode_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 100\n",
    "running_avg_1 = np.convolve(episode_rewards_smdp, np.ones(window_size)/window_size, mode='valid')\n",
    "running_avg_2 = np.convolve(episode_rewards_ioql, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "# Plot the running averages of both reward lists\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "ax.plot(range(1, len(running_avg_1) + 1), running_avg_1, label='SMDP', color='blue')\n",
    "ax.plot(range(1, len(running_avg_2) + 1), running_avg_2, label='Intra-QLearning', color='orange')\n",
    "\n",
    "ax.set_xlabel('Episodes')\n",
    "ax.set_ylabel('Running Average')\n",
    "ax.set_title('Running Average of Two Reward Lists')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
